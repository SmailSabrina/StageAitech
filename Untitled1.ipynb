{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean :11.638254101198871\n",
      "VAR : 8.46079567787654\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"data2/produc(no nul).csv\")\n",
    "categ= pd.get_dummies(data, columns=[\"Area\"]) \n",
    "#categ.head()\n",
    "data= pd.merge(data,categ,how=\"inner\")\n",
    "###\n",
    "categ= pd.get_dummies(data, columns=[\"Item\"]) \n",
    "#categ.head()\n",
    "data= pd.merge(data,categ,how=\"inner\")\n",
    "\n",
    "###droping columns\n",
    "X=data.drop([\"Area\",\"Production(t/ha)\",\"Item\",\"Unnamed: 0\",\"Unnamed: 0.1\"],axis=1)\n",
    "Y=data[\"Production(t/ha)\"]\n",
    "mean_y=np.mean(Y)\n",
    "std_var=np.var(Y)**(1/2)\n",
    "print(\"Mean :\"+str(mean_y))\n",
    "print(\"VAR : \"+str(std_var))\n",
    "#normalizing target data\n",
    "Y=(Y-mean_y)/std_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,Y, test_size = 0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:31:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:31:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:31:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:31:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:31:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('xgb',\n",
       "                               XGBRegressor(learning_rate=0.02, max_depth=2)),\n",
       "                              ('lgbm',\n",
       "                               LGBMRegressor(bagging_fraction=0.75,\n",
       "                                             bagging_freq=5, bagging_seed=7,\n",
       "                                             feature_fraction=0.4,\n",
       "                                             learning_rate=0.01, max_bin=200,\n",
       "                                             n_estimators=12000, num_leaves=4,\n",
       "                                             objective='regression'))],\n",
       "                  final_estimator=RandomForestRegressor())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "\n",
    "estimators =  [('xgb',xgb.XGBRegressor(n_estimators  = 100,learning_rate = 0.02, max_depth = 2)),\n",
    "               ('lgbm',LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=12000, \n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.4, \n",
    "                                       ))]\n",
    "\n",
    "ensemble = StackingRegressor(estimators      =  estimators,\n",
    "                             final_estimator =  RandomForestRegressor())\n",
    "\n",
    "# Fit ensemble using cross-validation\n",
    "ensemble.fit(X_train.values, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error train = 0.5283905516661614\n",
      "Root Mean Square Error test = 0.5755622391074307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Prediction\n",
    "predictions = ensemble.predict(X_train.values)\n",
    "print('Root Mean Square Error train = ' + str(math.sqrt(mean_squared_error(y_train, predictions))))\n",
    "# Prediction\n",
    "predictions = ensemble.predict(X_test.values)\n",
    "print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(y_test, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error test = 0.39740929250081297\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "predictions = ensemble.predict(X_train.values)\n",
    "print('Root Mean Square Error test = ' + str(math.sqrt(mean_squared_error(y_train, predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error test = 0.7332792212596738\n",
      "Root Mean Square Error train = 0.7114396608593495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "clf = ExtraTreesRegressor(n_estimators=1000, max_depth=8,min_samples_split=2, random_state=2)\n",
    "# Fit rf to the training set    \n",
    "clf.fit(X_train.values,y_train) \n",
    "# \n",
    "predict1 = clf.predict(X_test)\n",
    "predict2 = clf.predict(X_train)\n",
    "print('Root Mean Square Error test = ' + str(math.sqrt((MSE(y_test, predict1)))))\n",
    "print('Root Mean Square Error train = ' + str(math.sqrt((MSE(y_train, predict2)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
